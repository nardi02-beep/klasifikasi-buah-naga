{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5b18985-d0a5-42d1-aec3-825ccdfbffc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model loaded: knn_buah_naga_optimized.pkl\n",
      "   Classes: ['belum_matang' 'matang_sempurna' 'setengah_matang']\n",
      "\n",
      "======================================================================\n",
      "üî¥ AUTO-CAPTURE V4 - Red Dragon Fruit Detection\n",
      "======================================================================\n",
      "Model: knn_buah_naga_optimized.pkl\n",
      "Confidence: 65.0%\n",
      "Color area: ‚â•12.0%\n",
      "Variance range: 150-2000 (reject screen if > 2000)\n",
      "\n",
      "Optimized for:\n",
      "  ‚úÖ Dark red (mature)\n",
      "  ‚úÖ Bright red (ripe)\n",
      "  ‚úÖ Pink (less mature)\n",
      "  ‚úÖ Glossy surface\n",
      "  ‚ùå Screen/Display (auto reject)\n",
      "\n",
      "Controls: q=quit, m=manual, r=reset, +/-=threshold\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "[üì∏ CAPTURED] auto_captures\\matang_sempurna\\matang_sempurna_100_20251105_212348.jpg\n",
      "   matang_sempurna | 100.0% | Color: 42.7%\n",
      "\n",
      "[üì∏ CAPTURED] auto_captures\\matang_sempurna\\matang_sempurna_100_20251105_212352.jpg\n",
      "   matang_sempurna | 100.0% | Color: 42.0%\n",
      "\n",
      "[üì∏ CAPTURED] auto_captures\\matang_sempurna\\matang_sempurna_96_20251105_212357.jpg\n",
      "   matang_sempurna | 96.1% | Color: 49.1%\n",
      "\n",
      "[üì∏ CAPTURED] auto_captures\\matang_sempurna\\matang_sempurna_72_20251105_212400.jpg\n",
      "   matang_sempurna | 72.1% | Color: 41.7%\n",
      "\n",
      "[üì∏ CAPTURED] auto_captures\\matang_sempurna\\matang_sempurna_79_20251105_212417.jpg\n",
      "   matang_sempurna | 79.5% | Color: 45.3%\n",
      "\n",
      "[üì∏ CAPTURED] auto_captures\\matang_sempurna\\matang_sempurna_68_20251105_212425.jpg\n",
      "   matang_sempurna | 68.1% | Color: 52.1%\n",
      "\n",
      "[üì∏ CAPTURED] auto_captures\\belum_matang\\belum_matang_66_20251105_212432.jpg\n",
      "   belum_matang | 66.3% | Color: 41.8%\n",
      "\n",
      "[üì∏ CAPTURED] auto_captures\\belum_matang\\belum_matang_67_20251105_212444.jpg\n",
      "   belum_matang | 67.0% | Color: 41.5%\n",
      "\n",
      "[üì∏ CAPTURED] auto_captures\\belum_matang\\belum_matang_67_20251105_212452.jpg\n",
      "   belum_matang | 67.4% | Color: 30.8%\n",
      "\n",
      "[üì∏ CAPTURED] auto_captures\\matang_sempurna\\matang_sempurna_70_20251105_212456.jpg\n",
      "   matang_sempurna | 69.9% | Color: 32.0%\n",
      "\n",
      "[üì∏ CAPTURED] auto_captures\\matang_sempurna\\matang_sempurna_69_20251105_212459.jpg\n",
      "   matang_sempurna | 69.0% | Color: 29.7%\n",
      "\n",
      "[üì∏ CAPTURED] auto_captures\\matang_sempurna\\matang_sempurna_69_20251105_212513.jpg\n",
      "   matang_sempurna | 69.1% | Color: 43.2%\n",
      "\n",
      "[üì∏ CAPTURED] auto_captures\\matang_sempurna\\matang_sempurna_70_20251105_212517.jpg\n",
      "   matang_sempurna | 70.4% | Color: 36.5%\n",
      "\n",
      "[üì∏ CAPTURED] auto_captures\\matang_sempurna\\matang_sempurna_70_20251105_212527.jpg\n",
      "   matang_sempurna | 70.2% | Color: 46.4%\n",
      "\n",
      "[üì∏ CAPTURED] auto_captures\\matang_sempurna\\matang_sempurna_70_20251105_212600.jpg\n",
      "   matang_sempurna | 70.2% | Color: 40.7%\n",
      "\n",
      "======================================================================\n",
      "Stopped | Frames: 3771 | Captures: 5\n",
      "  21:24:59 | matang_sempurna (69.0%)\n",
      "  21:25:13 | matang_sempurna (69.1%)\n",
      "  21:25:17 | matang_sempurna (70.4%)\n",
      "  21:25:27 | matang_sempurna (70.2%)\n",
      "  21:26:00 | matang_sempurna (70.2%)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "üî¥ AUTO-CAPTURE V4 - OPTIMIZED for RED Dragon Fruit Detection\n",
    "FIXED: Deteksi buah naga merah ASLI (glossy, dark, berbagai pencahayaan)\n",
    "\n",
    "Key Improvements:\n",
    "1. ‚úÖ Expanded RED color range (cover dark & bright red)\n",
    "2. ‚úÖ Brightness normalization (consistent detection)\n",
    "3. ‚úÖ Very lenient object detection (for glossy surface)\n",
    "4. ‚úÖ Lower area threshold (12% instead of 20%)\n",
    "5. ‚úÖ Reject screen/display based on texture\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "from scipy.stats import skew\n",
    "from collections import deque\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------- 1. LOAD MODEL ----------\n",
    "MODEL_PATH = \"knn_buah_naga_optimized.pkl\"\n",
    "\n",
    "try:\n",
    "    model = joblib.load(MODEL_PATH)\n",
    "    print(f\"‚úÖ Model loaded: {MODEL_PATH}\")\n",
    "    \n",
    "    if hasattr(model, 'classes_'):\n",
    "        classes = model.classes_\n",
    "    elif hasattr(model, 'named_steps'):\n",
    "        knn = model.named_steps.get('knn')\n",
    "        classes = knn.classes_ if knn and hasattr(knn, 'classes_') else []\n",
    "    else:\n",
    "        classes = []\n",
    "    \n",
    "    print(f\"   Classes: {classes}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# ---------- 2. CONFIGURATION (OPTIMIZED FOR REAL FRUIT) ----------\n",
    "TARGET_SIZE = (800, 800)\n",
    "ROI_SIZE = 350\n",
    "CONFIDENCE_THRESHOLD = 65.0         # Lower threshold untuk real fruit\n",
    "CAPTURE_COOLDOWN = 3.0\n",
    "MOTION_THRESHOLD = 5000\n",
    "FRAME_BUFFER_SIZE = 7\n",
    "\n",
    "# üî¥ OPTIMIZED FOR RED DRAGON FRUIT\n",
    "MIN_DRAGON_FRUIT_AREA = 12.0        # 12% (turun dari 20%) - akomodasi refleksi\n",
    "MIN_VARIANCE = 150                   # Very lenient - glossy surface OK\n",
    "MIN_EDGE_DENSITY = 0.015             # Very lenient - smooth surface OK\n",
    "MAX_VARIANCE = 2000                  # NEW! Reject screen/display (texture terlalu tinggi)\n",
    "\n",
    "BASE_CAPTURE_DIR = \"auto_captures\"\n",
    "os.makedirs(BASE_CAPTURE_DIR, exist_ok=True)\n",
    "\n",
    "prediction_buffer = deque(maxlen=FRAME_BUFFER_SIZE)\n",
    "capture_history = deque(maxlen=5)\n",
    "last_capture_time = 0\n",
    "prev_frame_gray = None\n",
    "\n",
    "# ---------- 3. HELPER FUNCTIONS ----------\n",
    "def bgr_to_hsi(bgr_image):\n",
    "    \"\"\"BGR to HSI conversion\"\"\"\n",
    "    b = bgr_image[:, :, 0].astype(np.float32) / 255.0\n",
    "    g = bgr_image[:, :, 1].astype(np.float32) / 255.0\n",
    "    r = bgr_image[:, :, 2].astype(np.float32) / 255.0\n",
    "\n",
    "    i = (r + g + b) / 3.0\n",
    "    min_rgb = np.minimum(np.minimum(r, g), b)\n",
    "    denominator = r + g + b + 1e-6\n",
    "    s = 1 - (3.0 * min_rgb) / denominator\n",
    "    s = np.clip(s, 0, 1)\n",
    "\n",
    "    numerator = np.sqrt((r - g) ** 2 + (r - b) * (g - b))\n",
    "    valid = numerator > 1e-6\n",
    "    h = np.zeros_like(numerator)\n",
    "    cos_theta = np.where(valid, ((r - g) + (r - b)) / (2.0 * numerator + 1e-6), 1.0)\n",
    "    cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
    "    h = np.degrees(np.arccos(cos_theta))\n",
    "    h[b > g] = 360 - h[b > g]\n",
    "    h = np.clip(h, 0, 360)\n",
    "    return h, s, i\n",
    "\n",
    "def extract_color_features(bgr_img):\n",
    "    \"\"\"Extract 18 color features\"\"\"\n",
    "    img = cv2.resize(bgr_img, TARGET_SIZE, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    features = []\n",
    "    def get_stats(channel):\n",
    "        mean_val = np.mean(channel)\n",
    "        std_val = np.std(channel)\n",
    "        skew_val = skew(channel.flatten()) if std_val > 1e-6 else 0.0\n",
    "        return mean_val, std_val, skew_val\n",
    "    \n",
    "    b, g, r = cv2.split(img)\n",
    "    for channel in [r, g, b]:\n",
    "        features.extend(get_stats(channel))\n",
    "    \n",
    "    h, s, i_channel = bgr_to_hsi(img)\n",
    "    for channel in [h, s, i_channel]:\n",
    "        features.extend(get_stats(channel))\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# ---------- 4. MOTION DETECTION ----------\n",
    "def detect_motion(current_frame, prev_frame, roi_coords):\n",
    "    \"\"\"Motion detection\"\"\"\n",
    "    if prev_frame is None:\n",
    "        return True, 0\n",
    "    \n",
    "    x1, y1, x2, y2 = roi_coords\n",
    "    gray1 = cv2.cvtColor(current_frame[y1:y2, x1:x2], cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(prev_frame[y1:y2, x1:x2], cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    diff = cv2.absdiff(gray1, gray2)\n",
    "    _, thresh = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY)\n",
    "    changed_pixels = np.sum(thresh > 0)\n",
    "    \n",
    "    return changed_pixels > MOTION_THRESHOLD, changed_pixels\n",
    "\n",
    "# ---------- 5. PREDICTION ----------\n",
    "def predict_maturity(roi):\n",
    "    \"\"\"Predict with smoothing\"\"\"\n",
    "    try:\n",
    "        features = extract_color_features(roi)\n",
    "        label = model.predict([features])[0]\n",
    "        \n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            proba = model.predict_proba([features])[0]\n",
    "            confidence = np.max(proba) * 100\n",
    "            \n",
    "            if hasattr(model, 'classes_'):\n",
    "                classes = model.classes_\n",
    "            elif hasattr(model, 'named_steps'):\n",
    "                knn = model.named_steps.get('knn')\n",
    "                classes = knn.classes_ if knn else []\n",
    "            else:\n",
    "                classes = []\n",
    "            \n",
    "            class_probs = {cls: prob * 100 for cls, prob in zip(classes, proba)}\n",
    "        else:\n",
    "            confidence = 100.0\n",
    "            class_probs = {label: 100.0}\n",
    "        \n",
    "        prediction_buffer.append((label, confidence))\n",
    "        \n",
    "        labels = [pred[0] for pred in prediction_buffer]\n",
    "        from collections import Counter\n",
    "        label_counts = Counter(labels)\n",
    "        smoothed_label = label_counts.most_common(1)[0][0]\n",
    "        \n",
    "        confidences = [pred[1] for pred in prediction_buffer if pred[0] == smoothed_label]\n",
    "        smoothed_confidence = np.mean(confidences) if confidences else confidence\n",
    "        \n",
    "        return smoothed_label, smoothed_confidence, features, class_probs\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR]: {e}\")\n",
    "        return \"ERROR\", 0.0, None, {}\n",
    "\n",
    "# ---------- 6. üî¥ ENHANCED RED DRAGON FRUIT COLOR DETECTION ----------\n",
    "def is_dragon_fruit_color(roi):\n",
    "    \"\"\"\n",
    "    üî¥ OPTIMIZED untuk buah naga merah ASLI\n",
    "    \n",
    "    Covers:\n",
    "    - Dark red (mature): H=0-10, 170-180, S=20-100, V=30-90\n",
    "    - Bright red (ripe): H=0-15, 165-180, S=30-100, V=70-255\n",
    "    - Pink (immature): H=340-360, S=20-80, V=60-200\n",
    "    \n",
    "    Returns: (is_dragon_fruit, color_type, percentage, debug_info)\n",
    "    \"\"\"\n",
    "    # Brightness normalization untuk consistent detection\n",
    "    lab = cv2.cvtColor(roi, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b_ch = cv2.split(lab)\n",
    "    l = cv2.equalizeHist(l)  # Normalize luminance\n",
    "    lab_normalized = cv2.merge([l, a, b_ch])\n",
    "    roi_normalized = cv2.cvtColor(lab_normalized, cv2.COLOR_LAB2BGR)\n",
    "    \n",
    "    # Convert to HSV\n",
    "    hsv = cv2.cvtColor(roi_normalized, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # üî¥ RED COLOR RANGES (EXPANDED!)\n",
    "    \n",
    "    # Dark Red (mature dragon fruit) - merah gelap\n",
    "    # H: 0-10 & 170-180 (red wrap), S: 20-100 (akomodasi glossy), V: 30-90 (dark)\n",
    "    mask_dark_red1 = cv2.inRange(hsv, np.array([0, 20, 30]), np.array([10, 100, 90]))\n",
    "    mask_dark_red2 = cv2.inRange(hsv, np.array([170, 20, 30]), np.array([180, 100, 90]))\n",
    "    mask_dark_red = cv2.bitwise_or(mask_dark_red1, mask_dark_red2)\n",
    "    \n",
    "    # Bright Red (ripe dragon fruit) - merah cerah\n",
    "    # H: 0-15 & 165-180, S: 30-100, V: 70-255 (bright)\n",
    "    mask_bright_red1 = cv2.inRange(hsv, np.array([0, 30, 70]), np.array([15, 100, 255]))\n",
    "    mask_bright_red2 = cv2.inRange(hsv, np.array([165, 30, 70]), np.array([180, 100, 255]))\n",
    "    mask_bright_red = cv2.bitwise_or(mask_bright_red1, mask_bright_red2)\n",
    "    \n",
    "    # Pink/Light Red (less mature) - merah muda\n",
    "    # H: 0-5 & 175-180, S: 15-60, V: 80-255\n",
    "    mask_pink1 = cv2.inRange(hsv, np.array([0, 15, 80]), np.array([5, 60, 255]))\n",
    "    mask_pink2 = cv2.inRange(hsv, np.array([175, 15, 80]), np.array([180, 60, 255]))\n",
    "    mask_pink = cv2.bitwise_or(mask_pink1, mask_pink2)\n",
    "    \n",
    "    # Calculate percentages\n",
    "    total_pixels = roi.shape[0] * roi.shape[1]\n",
    "    dark_red_percent = (np.sum(mask_dark_red > 0) / total_pixels) * 100\n",
    "    bright_red_percent = (np.sum(mask_bright_red > 0) / total_pixels) * 100\n",
    "    pink_percent = (np.sum(mask_pink > 0) / total_pixels) * 100\n",
    "    \n",
    "    # Combine all red masks\n",
    "    mask_all_red = cv2.bitwise_or(mask_dark_red, mask_bright_red)\n",
    "    mask_all_red = cv2.bitwise_or(mask_all_red, mask_pink)\n",
    "    total_red_percent = (np.sum(mask_all_red > 0) / total_pixels) * 100\n",
    "    \n",
    "    # Also check for yellow/green (untuk buah naga kuning/putih)\n",
    "    mask_yellow = cv2.inRange(hsv, np.array([20, 30, 60]), np.array([40, 255, 255]))\n",
    "    mask_green = cv2.inRange(hsv, np.array([40, 20, 40]), np.array([80, 180, 220]))\n",
    "    \n",
    "    yellow_percent = (np.sum(mask_yellow > 0) / total_pixels) * 100\n",
    "    green_percent = (np.sum(mask_green > 0) / total_pixels) * 100\n",
    "    \n",
    "    # Total dragon fruit color (red + yellow + green)\n",
    "    mask_dragon_fruit = cv2.bitwise_or(mask_all_red, mask_yellow)\n",
    "    mask_dragon_fruit = cv2.bitwise_or(mask_dragon_fruit, mask_green)\n",
    "    dragon_fruit_percent = (np.sum(mask_dragon_fruit > 0) / total_pixels) * 100\n",
    "    \n",
    "    # Determine color type\n",
    "    color_percentages = {\n",
    "        'Dark Red': dark_red_percent,\n",
    "        'Bright Red': bright_red_percent,\n",
    "        'Pink': pink_percent,\n",
    "        'Yellow': yellow_percent,\n",
    "        'Green': green_percent\n",
    "    }\n",
    "    dominant_color = max(color_percentages, key=color_percentages.get)\n",
    "    \n",
    "    # üéØ VALIDATION: Minimal 12% (turun dari 20%)\n",
    "    is_dragon_fruit = dragon_fruit_percent >= MIN_DRAGON_FRUIT_AREA\n",
    "    \n",
    "    debug_info = {\n",
    "        'dark_red': dark_red_percent,\n",
    "        'bright_red': bright_red_percent,\n",
    "        'pink': pink_percent,\n",
    "        'yellow': yellow_percent,\n",
    "        'green': green_percent,\n",
    "        'total_red': total_red_percent,\n",
    "        'total': dragon_fruit_percent\n",
    "    }\n",
    "    \n",
    "    return is_dragon_fruit, dominant_color, dragon_fruit_percent, debug_info\n",
    "\n",
    "# ---------- 7. OBJECT DETECTION (VERY LENIENT + REJECT SCREEN) ----------\n",
    "def is_object_present(roi):\n",
    "    \"\"\"\n",
    "    Object detection dengan:\n",
    "    - Very lenient threshold (buah asli OK)\n",
    "    - Reject screen/display (variance terlalu tinggi)\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
    "    variance = np.var(gray)\n",
    "    \n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    edge_density = np.sum(edges > 0) / edges.size\n",
    "    \n",
    "    # Check variance range\n",
    "    has_variance_ok = MIN_VARIANCE < variance < MAX_VARIANCE\n",
    "    has_edges_ok = edge_density > MIN_EDGE_DENSITY\n",
    "    \n",
    "    # Reject if variance TOO HIGH (likely screen/display)\n",
    "    is_screen = variance > MAX_VARIANCE\n",
    "    \n",
    "    is_valid_object = has_variance_ok and has_edges_ok and not is_screen\n",
    "    \n",
    "    return is_valid_object, variance, edge_density, is_screen\n",
    "\n",
    "# ---------- 8. AUTO-CAPTURE LOGIC ----------\n",
    "def auto_capture(roi, label, confidence, class_probs, color_valid, color_percent, is_screen):\n",
    "    \"\"\"\n",
    "    Auto capture with validation:\n",
    "    1. Not a screen/display\n",
    "    2. Dragon fruit color detected\n",
    "    3. High confidence\n",
    "    \"\"\"\n",
    "    global last_capture_time\n",
    "    \n",
    "    current_time = time.time()\n",
    "    time_since_last = current_time - last_capture_time\n",
    "    \n",
    "    # Reject screen/display\n",
    "    if is_screen:\n",
    "        return False, \"‚ùå Screen/Display detected (texture too high)\"\n",
    "    \n",
    "    # Color validation\n",
    "    if not color_valid:\n",
    "        return False, f\"‚ùå Color: {color_percent:.1f}% (need ‚â•{MIN_DRAGON_FRUIT_AREA}%)\"\n",
    "    \n",
    "    # Confidence check\n",
    "    if confidence < CONFIDENCE_THRESHOLD:\n",
    "        return False, f\"Low confidence: {confidence:.1f}%\"\n",
    "    \n",
    "    # Cooldown\n",
    "    if time_since_last < CAPTURE_COOLDOWN:\n",
    "        return False, f\"Cooldown: {CAPTURE_COOLDOWN - time_since_last:.1f}s\"\n",
    "    \n",
    "    # CAPTURE!\n",
    "    class_dir = os.path.join(BASE_CAPTURE_DIR, label)\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"{label}_{confidence:.0f}_{timestamp}.jpg\"\n",
    "    filepath = os.path.join(class_dir, filename)\n",
    "    \n",
    "    cv2.imwrite(filepath, roi)\n",
    "    last_capture_time = current_time\n",
    "    \n",
    "    capture_info = {\n",
    "        'time': datetime.now().strftime(\"%H:%M:%S\"),\n",
    "        'label': label,\n",
    "        'confidence': confidence,\n",
    "        'filename': filename\n",
    "    }\n",
    "    capture_history.append(capture_info)\n",
    "    \n",
    "    print(f\"\\n[üì∏ CAPTURED] {filepath}\")\n",
    "    print(f\"   {label} | {confidence:.1f}% | Color: {color_percent:.1f}%\")\n",
    "    \n",
    "    return True, \"‚úÖ Captured!\"\n",
    "\n",
    "# ---------- 9. VISUAL HELPERS ----------\n",
    "def get_color_by_status(color_valid, confidence, is_screen):\n",
    "    \"\"\"ROI box color\"\"\"\n",
    "    if is_screen:\n",
    "        return (0, 0, 255)        # Red - screen detected\n",
    "    elif not color_valid:\n",
    "        return (100, 100, 100)    # Gray - not dragon fruit\n",
    "    elif confidence >= CONFIDENCE_THRESHOLD:\n",
    "        return (0, 255, 0)        # Green - ready\n",
    "    else:\n",
    "        return (0, 255, 255)      # Yellow - low confidence\n",
    "\n",
    "def draw_status_panel(frame, label, confidence, class_probs, color_valid, color_info, obj_info):\n",
    "    \"\"\"Status panel with debug info\"\"\"\n",
    "    h, w = frame.shape[:2]\n",
    "    \n",
    "    overlay = frame.copy()\n",
    "    cv2.rectangle(overlay, (10, 10), (500, 420), (0, 0, 0), -1)\n",
    "    frame = cv2.addWeighted(overlay, 0.75, frame, 0.25, 0)\n",
    "    \n",
    "    y = 30\n",
    "    \n",
    "    # Title\n",
    "    cv2.putText(frame, \"AUTO-CAPTURE V4 - Red Dragon Fruit\", \n",
    "                (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (100, 200, 255), 2)\n",
    "    y += 35\n",
    "    \n",
    "    # Layer 1: Object Detection\n",
    "    cv2.putText(frame, \"Layer 1: Object Detection\", \n",
    "                (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)\n",
    "    y += 20\n",
    "    obj_present, variance, edge_density, is_screen = obj_info\n",
    "    \n",
    "    if is_screen:\n",
    "        status = \"REJECT - SCREEN\"\n",
    "        color = (0, 0, 255)\n",
    "    elif obj_present:\n",
    "        status = \"PASS\"\n",
    "        color = (0, 255, 0)\n",
    "    else:\n",
    "        status = \"FAIL\"\n",
    "        color = (0, 0, 255)\n",
    "    \n",
    "    cv2.putText(frame, f\"  Status: {status}\", \n",
    "                (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 1)\n",
    "    y += 18\n",
    "    cv2.putText(frame, f\"  Var:{variance:.0f} (range:{MIN_VARIANCE}-{MAX_VARIANCE}) Edge:{edge_density:.3f}\", \n",
    "                (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (180, 180, 180), 1)\n",
    "    y += 25\n",
    "    \n",
    "    # Layer 2: Color Validation\n",
    "    cv2.putText(frame, \"Layer 2: Red Color Detection (Enhanced)\", \n",
    "                (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)\n",
    "    y += 20\n",
    "    color_status = \"PASS\" if color_valid else \"FAIL\"\n",
    "    color_color = (0, 255, 0) if color_valid else (0, 0, 255)\n",
    "    cv2.putText(frame, f\"  Status: {color_status} | Total: {color_info['total']:.1f}%\", \n",
    "                (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, color_color, 1)\n",
    "    y += 18\n",
    "    cv2.putText(frame, f\"  Dark Red: {color_info['dark_red']:.1f}% | Bright Red: {color_info['bright_red']:.1f}%\", \n",
    "                (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (180, 180, 180), 1)\n",
    "    y += 16\n",
    "    cv2.putText(frame, f\"  Pink: {color_info['pink']:.1f}% | Total Red: {color_info['total_red']:.1f}%\", \n",
    "                (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (180, 180, 180), 1)\n",
    "    y += 16\n",
    "    cv2.putText(frame, f\"  Min Required: {MIN_DRAGON_FRUIT_AREA}%\", \n",
    "                (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (150, 150, 150), 1)\n",
    "    y += 25\n",
    "    \n",
    "    # Layer 3: KNN Prediction\n",
    "    cv2.putText(frame, \"Layer 3: KNN Prediction\", \n",
    "                (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)\n",
    "    y += 20\n",
    "    conf_status = \"PASS\" if confidence >= CONFIDENCE_THRESHOLD else \"FAIL\"\n",
    "    conf_color = (0, 255, 0) if confidence >= CONFIDENCE_THRESHOLD else (0, 165, 255)\n",
    "    cv2.putText(frame, f\"  Status: {conf_status} | Label: {label} ({confidence:.1f}%)\", \n",
    "                (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, conf_color, 1)\n",
    "    y += 22\n",
    "    \n",
    "    # Probabilities\n",
    "    for cls, prob in sorted(class_probs.items(), key=lambda x: x[1], reverse=True):\n",
    "        bar_width = int(prob * 3.5)\n",
    "        cv2.rectangle(frame, (20, y - 10), (20 + bar_width, y + 4), \n",
    "                     (0, 255, 0) if prob > 50 else (0, 165, 255), -1)\n",
    "        cv2.putText(frame, f\"  {cls}: {prob:.1f}%\", \n",
    "                   (160, y), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "        y += 18\n",
    "    \n",
    "    # Final result\n",
    "    y += 10\n",
    "    all_pass = obj_present and not is_screen and color_valid and confidence >= CONFIDENCE_THRESHOLD\n",
    "    if is_screen:\n",
    "        result = \"RESULT: Screen/Display Rejected\"\n",
    "        result_color = (0, 0, 255)\n",
    "    elif all_pass:\n",
    "        result = \"RESULT: READY TO CAPTURE!\"\n",
    "        result_color = (0, 255, 0)\n",
    "    else:\n",
    "        result = \"RESULT: Validation Failed\"\n",
    "        result_color = (0, 100, 255)\n",
    "    \n",
    "    cv2.putText(frame, result, \n",
    "                (20, y), cv2.FONT_HERSHEY_SIMPLEX, 0.55, result_color, 2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "def draw_capture_history(frame):\n",
    "    \"\"\"History panel\"\"\"\n",
    "    if len(capture_history) == 0:\n",
    "        return frame\n",
    "    \n",
    "    h, w = frame.shape[:2]\n",
    "    overlay = frame.copy()\n",
    "    panel_height = min(30 + len(capture_history) * 22, 180)\n",
    "    cv2.rectangle(overlay, (w - 450, h - panel_height - 10), \n",
    "                 (w - 10, h - 10), (0, 0, 0), -1)\n",
    "    frame = cv2.addWeighted(overlay, 0.75, frame, 0.25, 0)\n",
    "    \n",
    "    y = h - panel_height\n",
    "    cv2.putText(frame, \"CAPTURE HISTORY:\", \n",
    "                (w - 440, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (100, 200, 255), 1)\n",
    "    y += 20\n",
    "    \n",
    "    for cap in reversed(list(capture_history)):\n",
    "        text = f\"{cap['time']} | {cap['label']} ({cap['confidence']:.0f}%)\"\n",
    "        cv2.putText(frame, text, \n",
    "                   (w - 440, y), cv2.FONT_HERSHEY_SIMPLEX, 0.38, (200, 200, 200), 1)\n",
    "        y += 18\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# ---------- 10. MAIN LOOP ----------\n",
    "def main():\n",
    "    global prev_frame_gray, last_capture_time, CONFIDENCE_THRESHOLD\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"‚ùå Camera failed\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üî¥ AUTO-CAPTURE V4 - Red Dragon Fruit Detection\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Model: {MODEL_PATH}\")\n",
    "    print(f\"Confidence: {CONFIDENCE_THRESHOLD}%\")\n",
    "    print(f\"Color area: ‚â•{MIN_DRAGON_FRUIT_AREA}%\")\n",
    "    print(f\"Variance range: {MIN_VARIANCE}-{MAX_VARIANCE} (reject screen if > {MAX_VARIANCE})\")\n",
    "    print(\"\\nOptimized for:\")\n",
    "    print(\"  ‚úÖ Dark red (mature)\")\n",
    "    print(\"  ‚úÖ Bright red (ripe)\")\n",
    "    print(\"  ‚úÖ Pink (less mature)\")\n",
    "    print(\"  ‚úÖ Glossy surface\")\n",
    "    print(\"  ‚ùå Screen/Display (auto reject)\")\n",
    "    print(\"\\nControls: q=quit, m=manual, r=reset, +/-=threshold\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    frame_count = 0\n",
    "    fps_start = time.time()\n",
    "    fps = 0\n",
    "    \n",
    "    label, confidence, class_probs = \"WAITING\", 0.0, {}\n",
    "    color_valid, color_info = False, {}\n",
    "    obj_info = (False, 0, 0, False)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        h, w = frame.shape[:2]\n",
    "        \n",
    "        if frame_count % 30 == 0:\n",
    "            fps = 30 / (time.time() - fps_start)\n",
    "            fps_start = time.time()\n",
    "        \n",
    "        # ROI\n",
    "        size = ROI_SIZE\n",
    "        x1, y1 = (w - size) // 2, (h - size) // 2\n",
    "        x2, y2 = x1 + size, y1 + size\n",
    "        x1, y1 = max(0, x1), max(0, y1)\n",
    "        x2, y2 = min(w, x2), min(h, y2)\n",
    "        \n",
    "        roi = frame[y1:y2, x1:x2]\n",
    "        if roi.size == 0:\n",
    "            continue\n",
    "        \n",
    "        # Motion\n",
    "        motion_detected, _ = detect_motion(frame, prev_frame_gray, (x1, y1, x2, y2))\n",
    "        prev_frame_gray = frame.copy()\n",
    "        \n",
    "        # Layer 1: Object detection\n",
    "        obj_present, variance, edge_density, is_screen = is_object_present(roi)\n",
    "        obj_info = (obj_present, variance, edge_density, is_screen)\n",
    "        \n",
    "        # Layer 2: Color validation\n",
    "        if obj_present and not is_screen:\n",
    "            color_valid, dominant_color, color_percent, debug_info = is_dragon_fruit_color(roi)\n",
    "            color_info = debug_info\n",
    "            color_info['dominant'] = dominant_color\n",
    "            \n",
    "            # Layer 3: Prediction\n",
    "            if color_valid and (motion_detected or frame_count % 5 == 0):\n",
    "                label, confidence, _, class_probs = predict_maturity(roi)\n",
    "                \n",
    "                # Auto-capture\n",
    "                captured, status = auto_capture(roi, label, confidence, class_probs, \n",
    "                                               color_valid, color_percent, is_screen)\n",
    "                if captured:\n",
    "                    flash = np.ones_like(frame) * 255\n",
    "                    frame = cv2.addWeighted(frame, 0.6, flash, 0.4, 0)\n",
    "        else:\n",
    "            color_valid = False\n",
    "            color_info = {'dark_red': 0, 'bright_red': 0, 'pink': 0, 'yellow': 0, 'green': 0, 'total_red': 0, 'total': 0}\n",
    "            if is_screen:\n",
    "                label = \"SCREEN DETECTED\"\n",
    "            else:\n",
    "                label = \"NO OBJECT\"\n",
    "            confidence, class_probs = 0.0, {}\n",
    "        \n",
    "        # Draw ROI\n",
    "        box_color = get_color_by_status(color_valid, confidence, is_screen)\n",
    "        thickness = 4 if (color_valid and confidence >= CONFIDENCE_THRESHOLD and not is_screen) else 2\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, thickness)\n",
    "        \n",
    "        center_x, center_y = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "        cv2.drawMarker(frame, (center_x, center_y), box_color, cv2.MARKER_CROSS, 30, 3)\n",
    "        \n",
    "        # Status text\n",
    "        if is_screen:\n",
    "            status_text = \"SCREEN/DISPLAY DETECTED - REJECTED\"\n",
    "            status_color = (0, 0, 255)\n",
    "        elif not obj_present:\n",
    "            status_text = \"WAITING FOR OBJECT\"\n",
    "            status_color = (100, 100, 100)\n",
    "        elif not color_valid:\n",
    "            status_text = f\"NOT RED DRAGON FRUIT ({color_info['total']:.1f}%)\"\n",
    "            status_color = (0, 100, 255)\n",
    "        elif confidence < CONFIDENCE_THRESHOLD:\n",
    "            status_text = f\"LOW CONFIDENCE ({confidence:.1f}%)\"\n",
    "            status_color = (0, 255, 255)\n",
    "        else:\n",
    "            status_text = \"READY TO CAPTURE!\"\n",
    "            status_color = (0, 255, 0)\n",
    "        \n",
    "        cv2.putText(frame, status_text, (x1 - 100, y1 - 15), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.65, status_color, 2)\n",
    "        \n",
    "        # Panels\n",
    "        frame = draw_status_panel(frame, label, confidence, class_probs, \n",
    "                                 color_valid, color_info, obj_info)\n",
    "        frame = draw_capture_history(frame)\n",
    "        \n",
    "        # FPS\n",
    "        cv2.putText(frame, f\"FPS: {fps:.1f}\", (w - 120, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.imshow(\"Red Dragon Fruit Scanner V4\", frame)\n",
    "        \n",
    "        # Keyboard\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('m'):\n",
    "            if color_valid and confidence >= CONFIDENCE_THRESHOLD and not is_screen:\n",
    "                last_capture_time = 0\n",
    "                auto_capture(roi, label, confidence, class_probs, color_valid, color_info['total'], is_screen)\n",
    "        elif key == ord('r'):\n",
    "            capture_history.clear()\n",
    "        elif key == ord('+') or key == ord('='):\n",
    "            CONFIDENCE_THRESHOLD = min(95, CONFIDENCE_THRESHOLD + 5)\n",
    "            print(f\"[‚öôÔ∏è] Threshold: {CONFIDENCE_THRESHOLD}%\")\n",
    "        elif key == ord('-') or key == ord('_'):\n",
    "            CONFIDENCE_THRESHOLD = max(50, CONFIDENCE_THRESHOLD - 5)\n",
    "            print(f\"[‚öôÔ∏è] Threshold: {CONFIDENCE_THRESHOLD}%\")\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Stopped | Frames: {frame_count} | Captures: {len(capture_history)}\")\n",
    "    if len(capture_history) > 0:\n",
    "        for cap in capture_history:\n",
    "            print(f\"  {cap['time']} | {cap['label']} ({cap['confidence']:.1f}%)\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4998241f-7f9b-49cf-b2b5-b4673880367a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
